import os
import json
import requests
import shutil  # pour d√©placer les fichiers
from datetime import datetime

# === CONFIGURATION ===
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3"

positive_keywords = [
    "plausible", "int√©ressant", "coh√©rent", "prometteur", "profond",
    "fascinant", "√©tonnant", "innovant", "pertinent", "novateur",
    "convaincant", "solide", "√©l√©gant", "audacieux", "original",
    "remarquable", "excellent", "brillant", "stimulant",
    "80", "85", "90", "95", "100", "tr√®s bon", "bon potentiel"
]

def is_positive(analysis):
    return any(word in analysis.lower() for word in positive_keywords)

def consult_llm(formula_str, context_tag):
    prompt = f"""
    En tant que physicien th√©oricien de tr√®s haut niveau en 2025, analyse cette conjecture issue d'une √©volution agentique autonome :

    Formule : {formula_str}

    Inspiration : {context_tag}

    1. Ressemblance avec un concept connu ou √©mergent ?
    2. Coh√©rence th√©orique, √©l√©gance et audace ?
    3. Plausibilit√© sur 100 ?
    4. Potentiel comme avanc√©e partielle sur un probl√®me unsolved ?

    R√©ponds en fran√ßais, pr√©cis, technique, sans complaisance, et avec une note chiffr√©e.
    """
    try:
        payload = {"model": MODEL_NAME, "prompt": prompt, "stream": False}
        response = requests.post(OLLAMA_URL, json=payload, timeout=600)
        if response.status_code == 200:
            return response.json().get('response', "Pas de r√©ponse").strip()
        else:
            return f"Erreur HTTP {response.status_code}"
    except Exception as e:
        return f"Erreur LLM : {str(e)}"

# === CHARGEMENT DES D√âCOUVERTES √Ä ANALYSER (depuis omega_agents_logs) ===
discoveries = []
log_dir = "omega_agents_logs"

for filename in os.listdir(log_dir):
    if filename.startswith("discovery_p") and filename.endswith(".json"):
        file_path = os.path.join(log_dir, filename)
        with open(file_path, "r", encoding='utf-8') as f:
            data = json.load(f)
            # On analyse seulement celles pas encore critiqu√©es
            if "diff√©r√©e" in data.get("analysis", "") and 'true_analysis' not in data:
                discoveries.append((file_path, data))

# Tri par score
discoveries.sort(key=lambda x: x[1]['score'], reverse=True)

print(f"\n=== ANALYSE CRITIQUE DES {len(discoveries)} NOUVELLES CONJECTURES ===")
print(f"Date : {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")

N = min(100, len(discoveries))
moved_count = 0

for i, (source_path, d) in enumerate(discoveries[:N], 1):
    score = d['score']
    family = d.get('family', 'Uncategorized')
    subfamily = d.get('subfamily', 'General')

    print(f"#{i}/{N} | Score : {score} | Famille : {family}/{subfamily}")
    print(f"Formule : {d['formula']}")
    print(f"LaTeX : ${d['latex']}$")
    print(f"Inspiration : {d['inspiration']}\n")

    print("Critique th√©orique en cours...\n")
    true_analysis = consult_llm(d['formula'], d['inspiration'])
    print(f"{true_analysis}\n")

    if is_positive(true_analysis):
        print("üåü JUGEMENT POSITIF DU CRITIQUE TH√âORIQUE üåü\n")
    else:
        print("‚öñÔ∏è Jugement neutre ou r√©serv√©.\n")

    # === SAUVEGARDE DE L'ANALYSE ===
    d['true_analysis'] = true_analysis
    d['analysis_date'] = datetime.now().strftime("%Y-%m-%d %H:%M")

    # === D√âPLACEMENT VERS LE DOSSIER TH√âMATIQUE D√âFINITIF ===
    thematic_dir = f"discoveries_thematic/{family}/{subfamily}"
    os.makedirs(thematic_dir, exist_ok=True)
    final_path = os.path.join(thematic_dir, os.path.basename(source_path))

    with open(final_path, "w", encoding='utf-8') as f:
        json.dump(d, f, indent=4, ensure_ascii=False)

    # Suppression de la copie dans omega_agents_logs
    os.remove(source_path)

    print(f"‚Üí D√©plac√©e d√©finitivement vers {family}/{subfamily}/ et supprim√©e du dossier temporaire\n")
    moved_count += 1

    print("=" * 120)

    # === MISE √Ä JOUR DE LA M√âMOIRE CENTRALE DE L'HYDRE ===
    MEMORY_FILE = "hydra_memory.json"

    # Charge ou cr√©e la m√©moire
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            memory = json.load(f)
    else:
        memory = {"formulas": {}}

    # Met √† jour avec les formules analys√©es dans ce run
    for i, (source_path, d) in enumerate(discoveries[:N], 1):
        try:
            simplified = sp.simplify(sp.sympify(d['formula']))
            key = str(simplified)
        except:
            key = d['formula']

        status = "validated" if is_positive(d.get('true_analysis', '')) else "rejected"

        if key not in memory["formulas"]:
            memory["formulas"][key] = {
                "original": d['formula'],
                "simplified": key,
                "count": 1,
                "status": status,
                "last_seen": datetime.now().strftime("%Y-%m-%d"),
                "family": d.get('family', 'Unknown'),
                "subfamily": d.get('subfamily', 'Unknown'),
                "llm_judgment": d.get('true_analysis', 'Non analys√©e')
            }
        else:
            memory["formulas"][key]["count"] += 1
            memory["formulas"][key]["status"] = status
            memory["formulas"][key]["last_seen"] = datetime.now().strftime("%Y-%m-%d")
            if 'true_analysis' in d:
                memory["formulas"][key]["llm_judgment"] = d['true_analysis']

    # Sauvegarde
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, indent=4, ensure_ascii=False)

    print(f"\nM√©moire centrale mise √† jour : {len(memory['formulas'])} formules uniques connues.")

print(f"\nAnalyse termin√©e : {moved_count} conjectures analys√©es et archiv√©es d√©finitivement.")
print("omega_agents_logs est maintenant nettoy√© ‚Äî pr√™t pour le prochain run !")
print("Toutes les formules critiqu√©es sont dans discoveries_thematic/ (organis√©es par famille).")
